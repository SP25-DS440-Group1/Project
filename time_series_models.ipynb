{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Bidirectional, Conv1D, MaxPooling1D, Flatten, Concatenate\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"./data/X_train_lstm.csv\")\n",
    "X_test = pd.read_csv(\"./data/X_test_lstm.csv\")\n",
    "\n",
    "Y_train = pd.read_csv(\"./data/Y_train_lstm.csv\")\n",
    "Y_test = pd.read_csv(\"./data/Y_test_lstm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2873/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1912.3690 - mae: 21.0149\n",
      "Epoch 1: val_loss improved from inf to 474.74130, saving model to ./models/lstm_model.keras\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 14ms/step - loss: 1911.0349 - mae: 21.0067 - val_loss: 474.7413 - val_mae: 10.9901\n",
      "Epoch 2/50\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 495.1689 - mae: 11.0249\n",
      "Epoch 2: val_loss did not improve from 474.74130\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - loss: 495.1945 - mae: 11.0251 - val_loss: 494.6069 - val_mae: 10.4383\n",
      "Epoch 3/50\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 614.9430 - mae: 11.4525\n",
      "Epoch 3: val_loss improved from 474.74130 to 452.43716, saving model to ./models/lstm_model.keras\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - loss: 614.9241 - mae: 11.4525 - val_loss: 452.4372 - val_mae: 11.0214\n",
      "Epoch 4/50\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 545.8421 - mae: 11.4326\n",
      "Epoch 4: val_loss did not improve from 452.43716\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12ms/step - loss: 545.8994 - mae: 11.4328 - val_loss: 1408.0367 - val_mae: 27.0561\n",
      "Epoch 5/50\n",
      "\u001b[1m2875/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5761.5566 - mae: 20.4607\n",
      "Epoch 5: val_loss did not improve from 452.43716\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 11ms/step - loss: 5763.9614 - mae: 20.4621 - val_loss: 5998.7954 - val_mae: 57.7505\n",
      "Epoch 6/50\n",
      "\u001b[1m2873/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 27673.9395 - mae: 29.7719\n",
      "Epoch 6: val_loss improved from 452.43716 to 448.59543, saving model to ./models/lstm_model.keras\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12ms/step - loss: 27643.9336 - mae: 29.7534 - val_loss: 448.5954 - val_mae: 11.2916\n",
      "Epoch 7/50\n",
      "\u001b[1m2872/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 451.7376 - mae: 11.3897\n",
      "Epoch 7: val_loss did not improve from 448.59543\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - loss: 451.9153 - mae: 11.3907 - val_loss: 518.0148 - val_mae: 13.5614\n",
      "Epoch 8/50\n",
      "\u001b[1m2872/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 565.6840 - mae: 12.2772\n",
      "Epoch 8: val_loss did not improve from 448.59543\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - loss: 565.6371 - mae: 12.2772 - val_loss: 477.4937 - val_mae: 14.0046\n",
      "Epoch 9/50\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 850.1282 - mae: 13.3544\n",
      "Epoch 9: val_loss improved from 448.59543 to 442.21274, saving model to ./models/lstm_model.keras\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 12ms/step - loss: 850.0933 - mae: 13.3543 - val_loss: 442.2127 - val_mae: 11.3820\n",
      "Epoch 10/50\n",
      "\u001b[1m2871/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 500.4792 - mae: 12.0117\n",
      "Epoch 10: val_loss did not improve from 442.21274\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - loss: 500.5522 - mae: 12.0115 - val_loss: 460.4195 - val_mae: 12.2773\n",
      "Epoch 11/50\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1437.3636 - mae: 14.2529\n",
      "Epoch 11: val_loss did not improve from 442.21274\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12ms/step - loss: 1437.1763 - mae: 14.2525 - val_loss: 445.5856 - val_mae: 12.1026\n",
      "Epoch 12/50\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 442.9501 - mae: 11.9252\n",
      "Epoch 12: val_loss did not improve from 442.21274\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12ms/step - loss: 442.9477 - mae: 11.9251 - val_loss: 536.8278 - val_mae: 15.6451\n",
      "Epoch 13/50\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3017.5715 - mae: 18.3963\n",
      "Epoch 13: val_loss did not improve from 442.21274\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - loss: 3018.1675 - mae: 18.3967 - val_loss: 467.1992 - val_mae: 13.1469\n",
      "Epoch 14/50\n",
      "\u001b[1m2871/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6844.2188 - mae: 18.0019\n",
      "Epoch 14: val_loss did not improve from 442.21274\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - loss: 6845.1890 - mae: 18.0051 - val_loss: 451.5130 - val_mae: 12.5524\n",
      "Epoch 14: early stopping\n",
      "\u001b[1m9924/9924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 406.7344 - mae: 12.0425\n",
      "Test Mean Absolute Error: 11.757591247558594\n",
      "\u001b[1m9924/9924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      "Mean Absolute Error for each column:\n",
      "[17.586514   7.588531   1.0059724 11.797486  20.812899 ]\n"
     ]
    }
   ],
   "source": [
    "# Defining callbacks\n",
    "checkpoint = ModelCheckpoint(\"./models/lstm_model.keras\", monitor='val_loss', save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "# Define LSTM model\n",
    "# Up to 2 layers of LSTM and number of hidden units were hand tuned to determine this as the optimum model\n",
    "lstm_model = Sequential([\n",
    "    Input(shape=(X_train.shape[1], 1)),\n",
    "    LSTM(units=64, activation='relu', recurrent_dropout=0.2),\n",
    "    Dense(5)\n",
    "])\n",
    "\n",
    "# Use MSE for loss because we want to emphasize the \"wrongest\" guesses the most. MAE is an interpretable metric\n",
    "lstm_model.compile(optimizer=Adam(learning_rate=1e-3), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train model w/ early stopping\n",
    "# Batch size is the average number of flights per day\n",
    "history = lstm_model.fit(X_train, Y_train, epochs=50, batch_size=265, validation_split=0.2, callbacks=[checkpoint, early_stopping])\n",
    "\n",
    "\n",
    "loss, mae = lstm_model.evaluate(X_test, Y_test)\n",
    "print(\"Test Mean Absolute Error:\", mae)\n",
    "\n",
    "Y_pred = lstm_model.predict(X_test)\n",
    "\n",
    "mae_columns = mean_absolute_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "print(\"Mean Absolute Error for each column:\")\n",
    "print(mae_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2874/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1821.3560 - mae: 20.9371\n",
      "Epoch 1: val_loss improved from inf to 395.48599, saving model to ./models/bilstm_model.keras\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 18ms/step - loss: 1820.2422 - mae: 20.9299 - val_loss: 395.4860 - val_mae: 11.1859\n",
      "Epoch 2/50\n",
      "\u001b[1m2875/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 378.2658 - mae: 10.5549\n",
      "Epoch 2: val_loss improved from 395.48599 to 389.07269, saving model to ./models/bilstm_model.keras\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 17ms/step - loss: 378.2642 - mae: 10.5549 - val_loss: 389.0727 - val_mae: 10.6232\n",
      "Epoch 3/50\n",
      "\u001b[1m2875/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 384.2144 - mae: 10.5152\n",
      "Epoch 3: val_loss improved from 389.07269 to 387.34839, saving model to ./models/bilstm_model.keras\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 16ms/step - loss: 384.2145 - mae: 10.5152 - val_loss: 387.3484 - val_mae: 10.5755\n",
      "Epoch 4/50\n",
      "\u001b[1m2874/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 382.8504 - mae: 10.5915\n",
      "Epoch 4: val_loss improved from 387.34839 to 384.87027, saving model to ./models/bilstm_model.keras\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 16ms/step - loss: 382.8465 - mae: 10.5914 - val_loss: 384.8703 - val_mae: 10.6422\n",
      "Epoch 5/50\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 389.3168 - mae: 10.7589\n",
      "Epoch 5: val_loss did not improve from 384.87027\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 16ms/step - loss: 389.3171 - mae: 10.7589 - val_loss: 395.3443 - val_mae: 11.2539\n",
      "Epoch 6/50\n",
      "\u001b[1m2874/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 731.5940 - mae: 13.5064\n",
      "Epoch 6: val_loss improved from 384.87027 to 384.82605, saving model to ./models/bilstm_model.keras\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 16ms/step - loss: 731.4811 - mae: 13.5055 - val_loss: 384.8260 - val_mae: 10.5482\n",
      "Epoch 7/50\n",
      "\u001b[1m2873/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 398.1581 - mae: 10.9970\n",
      "Epoch 7: val_loss improved from 384.82605 to 382.75571, saving model to ./models/bilstm_model.keras\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 17ms/step - loss: 398.1462 - mae: 10.9966 - val_loss: 382.7557 - val_mae: 10.6900\n",
      "Epoch 8/50\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5216.8896 - mae: 13.9502\n",
      "Epoch 8: val_loss did not improve from 382.75571\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 16ms/step - loss: 5226.1895 - mae: 13.9530 - val_loss: 505.0972 - val_mae: 14.0761\n",
      "Epoch 9/50\n",
      "\u001b[1m2874/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 10718.5303 - mae: 27.0659\n",
      "Epoch 9: val_loss did not improve from 382.75571\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 17ms/step - loss: 10714.1787 - mae: 27.0570 - val_loss: 457.6050 - val_mae: 13.8028\n",
      "Epoch 10/50\n",
      "\u001b[1m2874/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 52281.6836 - mae: 33.9047\n",
      "Epoch 10: val_loss did not improve from 382.75571\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 17ms/step - loss: 52254.2539 - mae: 33.8946 - val_loss: 444.2033 - val_mae: 12.5246\n",
      "Epoch 11/50\n",
      "\u001b[1m2874/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3008.4299 - mae: 14.5955\n",
      "Epoch 11: val_loss did not improve from 382.75571\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 16ms/step - loss: 3007.6975 - mae: 14.5953 - val_loss: 440.8908 - val_mae: 12.2735\n",
      "Epoch 12/50\n",
      "\u001b[1m2875/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10404.1650 - mae: 16.3630\n",
      "Epoch 12: val_loss did not improve from 382.75571\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 16ms/step - loss: 10415.4453 - mae: 16.3649 - val_loss: 1772.7939 - val_mae: 33.7843\n",
      "Epoch 12: early stopping\n",
      "\u001b[1m9924/9924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 1614.1936 - mae: 32.7685\n",
      "Test Mean Absolute Error: 32.96731185913086\n",
      "\u001b[1m9924/9924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step\n",
      "Mean Absolute Error for each column:\n",
      "[33.75294  37.853714 21.098156 51.25307  20.879248]\n"
     ]
    }
   ],
   "source": [
    "# Defining callbacks\n",
    "checkpoint = ModelCheckpoint(\"./models/bilstm_model.keras\", monitor='val_loss', save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "# Define LSTM model\n",
    "# Up to 2 layers of LSTM and number of hidden units were hand tuned to determine this as the optimum model\n",
    "bilstm_model = Sequential([\n",
    "    Input(shape=(X_train.shape[1], 1)),\n",
    "    Bidirectional(\n",
    "        LSTM(units=64, activation='relu', recurrent_dropout=0.2)\n",
    "    ),\n",
    "    Dense(5)\n",
    "])\n",
    "\n",
    "# Use MSE for loss because we want to emphasize the \"wrongest\" guesses the most. MAE is an interpretable metric\n",
    "bilstm_model.compile(optimizer=Adam(learning_rate=1e-3), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train model w/ early stopping\n",
    "# Batch size is the average number of flights per day\n",
    "history = bilstm_model.fit(X_train, Y_train, epochs=50, batch_size=265, validation_split=0.2, callbacks=[checkpoint, early_stopping])\n",
    "\n",
    "\n",
    "loss, mae = bilstm_model.evaluate(X_test, Y_test)\n",
    "print(\"Test Mean Absolute Error:\", mae)\n",
    "\n",
    "Y_pred = bilstm_model.predict(X_test)\n",
    "\n",
    "mae_columns = mean_absolute_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "print(\"Mean Absolute Error for each column:\")\n",
    "print(mae_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN + LSTM Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1487/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 551.3322 - mae: 12.9745\n",
      "Epoch 1: val_loss improved from inf to 394.40552, saving model to ./models/hybrid_model.keras\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 551.0410 - mae: 12.9706 - val_loss: 394.4055 - val_mae: 10.6622\n",
      "Epoch 2/50\n",
      "\u001b[1m1487/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 367.5835 - mae: 10.2510\n",
      "Epoch 2: val_loss improved from 394.40552 to 387.63156, saving model to ./models/hybrid_model.keras\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 22ms/step - loss: 367.5815 - mae: 10.2510 - val_loss: 387.6316 - val_mae: 10.6408\n",
      "Epoch 3/50\n",
      "\u001b[1m1488/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 362.9244 - mae: 10.1256\n",
      "Epoch 3: val_loss did not improve from 387.63156\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 22ms/step - loss: 362.9236 - mae: 10.1256 - val_loss: 388.3692 - val_mae: 10.4858\n",
      "Epoch 4/50\n",
      "\u001b[1m1488/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 359.7726 - mae: 10.0536\n",
      "Epoch 4: val_loss improved from 387.63156 to 381.05737, saving model to ./models/hybrid_model.keras\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - loss: 359.7703 - mae: 10.0536 - val_loss: 381.0574 - val_mae: 10.5371\n",
      "Epoch 5/50\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 355.7694 - mae: 9.9333\n",
      "Epoch 5: val_loss did not improve from 381.05737\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 22ms/step - loss: 355.7696 - mae: 9.9333 - val_loss: 386.5383 - val_mae: 10.5516\n",
      "Epoch 6/50\n",
      "\u001b[1m1487/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 355.7990 - mae: 9.9343\n",
      "Epoch 6: val_loss improved from 381.05737 to 376.67499, saving model to ./models/hybrid_model.keras\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - loss: 355.7949 - mae: 9.9342 - val_loss: 376.6750 - val_mae: 10.4272\n",
      "Epoch 7/50\n",
      "\u001b[1m1487/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 352.6774 - mae: 9.8282\n",
      "Epoch 7: val_loss improved from 376.67499 to 373.10654, saving model to ./models/hybrid_model.keras\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 22ms/step - loss: 352.6761 - mae: 9.8282 - val_loss: 373.1065 - val_mae: 10.3778\n",
      "Epoch 8/50\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 350.7485 - mae: 9.7609\n",
      "Epoch 8: val_loss did not improve from 373.10654\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 350.7484 - mae: 9.7609 - val_loss: 374.2157 - val_mae: 10.5054\n",
      "Epoch 9/50\n",
      "\u001b[1m1487/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 349.5699 - mae: 9.7075\n",
      "Epoch 9: val_loss improved from 373.10654 to 372.45023, saving model to ./models/hybrid_model.keras\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 349.5690 - mae: 9.7075 - val_loss: 372.4502 - val_mae: 10.3177\n",
      "Epoch 10/50\n",
      "\u001b[1m1488/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 348.5083 - mae: 9.6639\n",
      "Epoch 10: val_loss improved from 372.45023 to 372.04611, saving model to ./models/hybrid_model.keras\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 348.5079 - mae: 9.6639 - val_loss: 372.0461 - val_mae: 10.3628\n",
      "Epoch 11/50\n",
      "\u001b[1m1486/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 348.1519 - mae: 9.6435\n",
      "Epoch 11: val_loss improved from 372.04611 to 370.82330, saving model to ./models/hybrid_model.keras\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 22ms/step - loss: 348.1514 - mae: 9.6435 - val_loss: 370.8233 - val_mae: 10.1544\n",
      "Epoch 12/50\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 348.1252 - mae: 9.6319\n",
      "Epoch 12: val_loss did not improve from 370.82330\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 22ms/step - loss: 348.1249 - mae: 9.6319 - val_loss: 370.8961 - val_mae: 10.1093\n",
      "Epoch 13/50\n",
      "\u001b[1m1487/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 346.8976 - mae: 9.5979\n",
      "Epoch 13: val_loss improved from 370.82330 to 370.25366, saving model to ./models/hybrid_model.keras\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 22ms/step - loss: 346.8968 - mae: 9.5979 - val_loss: 370.2537 - val_mae: 9.9970\n",
      "Epoch 14/50\n",
      "\u001b[1m1488/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 345.8948 - mae: 9.5729\n",
      "Epoch 14: val_loss did not improve from 370.25366\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 22ms/step - loss: 345.8944 - mae: 9.5729 - val_loss: 370.3553 - val_mae: 10.0070\n",
      "Epoch 15/50\n",
      "\u001b[1m1487/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 345.3246 - mae: 9.5573\n",
      "Epoch 15: val_loss improved from 370.25366 to 369.50580, saving model to ./models/hybrid_model.keras\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 22ms/step - loss: 345.3239 - mae: 9.5573 - val_loss: 369.5058 - val_mae: 9.9899\n",
      "Epoch 16/50\n",
      "\u001b[1m1487/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 344.9915 - mae: 9.5496\n",
      "Epoch 16: val_loss improved from 369.50580 to 369.17407, saving model to ./models/hybrid_model.keras\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 344.9909 - mae: 9.5496 - val_loss: 369.1741 - val_mae: 10.0558\n",
      "Epoch 17/50\n",
      "\u001b[1m1487/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 344.3445 - mae: 9.5333\n",
      "Epoch 17: val_loss improved from 369.17407 to 369.07864, saving model to ./models/hybrid_model.keras\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 22ms/step - loss: 344.3440 - mae: 9.5333 - val_loss: 369.0786 - val_mae: 10.0958\n",
      "Epoch 18/50\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 343.9366 - mae: 9.5233\n",
      "Epoch 18: val_loss did not improve from 369.07864\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 343.9365 - mae: 9.5233 - val_loss: 372.6269 - val_mae: 10.1982\n",
      "Epoch 19/50\n",
      "\u001b[1m1487/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 343.7719 - mae: 9.5214\n",
      "Epoch 19: val_loss did not improve from 369.07864\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 343.7707 - mae: 9.5214 - val_loss: 370.1378 - val_mae: 10.2038\n",
      "Epoch 20/50\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 343.1842 - mae: 9.5091\n",
      "Epoch 20: val_loss did not improve from 369.07864\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 24ms/step - loss: 343.1849 - mae: 9.5091 - val_loss: 376.9597 - val_mae: 10.2803\n",
      "Epoch 21/50\n",
      "\u001b[1m1487/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 349.1698 - mae: 9.6621\n",
      "Epoch 21: val_loss improved from 369.07864 to 368.96762, saving model to ./models/hybrid_model.keras\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 26ms/step - loss: 349.1631 - mae: 9.6619 - val_loss: 368.9676 - val_mae: 10.1608\n",
      "Epoch 22/50\n",
      "\u001b[1m1487/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 342.9118 - mae: 9.5041\n",
      "Epoch 22: val_loss improved from 368.96762 to 368.52234, saving model to ./models/hybrid_model.keras\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 26ms/step - loss: 342.9130 - mae: 9.5041 - val_loss: 368.5223 - val_mae: 10.1960\n",
      "Epoch 23/50\n",
      "\u001b[1m1487/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 342.3702 - mae: 9.4920\n",
      "Epoch 23: val_loss improved from 368.52234 to 368.04568, saving model to ./models/hybrid_model.keras\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 26ms/step - loss: 342.3697 - mae: 9.4919 - val_loss: 368.0457 - val_mae: 10.1584\n",
      "Epoch 24/50\n",
      "\u001b[1m1487/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 342.1375 - mae: 9.4907\n",
      "Epoch 24: val_loss did not improve from 368.04568\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 26ms/step - loss: 342.1374 - mae: 9.4907 - val_loss: 368.0563 - val_mae: 10.1300\n",
      "Epoch 25/50\n",
      "\u001b[1m1487/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 341.9222 - mae: 9.4850\n",
      "Epoch 25: val_loss improved from 368.04568 to 367.88809, saving model to ./models/hybrid_model.keras\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 26ms/step - loss: 341.9216 - mae: 9.4850 - val_loss: 367.8881 - val_mae: 10.1328\n",
      "Epoch 26/50\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 342.7500 - mae: 9.5088\n",
      "Epoch 26: val_loss did not improve from 367.88809\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 25ms/step - loss: 342.7505 - mae: 9.5088 - val_loss: 368.1425 - val_mae: 10.1430\n",
      "Epoch 27/50\n",
      "\u001b[1m1487/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 343.9745 - mae: 9.5389\n",
      "Epoch 27: val_loss did not improve from 367.88809\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 25ms/step - loss: 343.9782 - mae: 9.5390 - val_loss: 373.3929 - val_mae: 10.3107\n",
      "Epoch 28/50\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 341.6506 - mae: 9.4859\n",
      "Epoch 28: val_loss improved from 367.88809 to 367.83649, saving model to ./models/hybrid_model.keras\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 24ms/step - loss: 341.6505 - mae: 9.4859 - val_loss: 367.8365 - val_mae: 10.1428\n",
      "Epoch 29/50\n",
      "\u001b[1m1488/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 340.8942 - mae: 9.4651\n",
      "Epoch 29: val_loss did not improve from 367.83649\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 25ms/step - loss: 340.8940 - mae: 9.4651 - val_loss: 368.5144 - val_mae: 10.0926\n",
      "Epoch 30/50\n",
      "\u001b[1m1488/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 340.6533 - mae: 9.4604\n",
      "Epoch 30: val_loss did not improve from 367.83649\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 25ms/step - loss: 340.6531 - mae: 9.4604 - val_loss: 368.1025 - val_mae: 10.1248\n",
      "Epoch 31/50\n",
      "\u001b[1m1488/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 340.6638 - mae: 9.4625\n",
      "Epoch 31: val_loss did not improve from 367.83649\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 25ms/step - loss: 340.6637 - mae: 9.4625 - val_loss: 368.4593 - val_mae: 10.1224\n",
      "Epoch 32/50\n",
      "\u001b[1m1487/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 340.6736 - mae: 9.4625\n",
      "Epoch 32: val_loss improved from 367.83649 to 367.77249, saving model to ./models/hybrid_model.keras\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 25ms/step - loss: 340.6734 - mae: 9.4625 - val_loss: 367.7725 - val_mae: 10.1291\n",
      "Epoch 33/50\n",
      "\u001b[1m1486/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 340.6157 - mae: 9.4596\n",
      "Epoch 33: val_loss did not improve from 367.77249\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 24ms/step - loss: 340.6149 - mae: 9.4596 - val_loss: 371.2554 - val_mae: 10.2502\n",
      "Epoch 34/50\n",
      "\u001b[1m1488/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 340.5852 - mae: 9.4617\n",
      "Epoch 34: val_loss did not improve from 367.77249\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - loss: 340.5846 - mae: 9.4617 - val_loss: 368.0359 - val_mae: 10.1300\n",
      "Epoch 35/50\n",
      "\u001b[1m1487/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 339.9341 - mae: 9.4522\n",
      "Epoch 35: val_loss improved from 367.77249 to 367.44455, saving model to ./models/hybrid_model.keras\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 22ms/step - loss: 339.9338 - mae: 9.4521 - val_loss: 367.4445 - val_mae: 10.1189\n",
      "Epoch 36/50\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 339.6926 - mae: 9.4419\n",
      "Epoch 36: val_loss did not improve from 367.44455\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - loss: 339.6925 - mae: 9.4419 - val_loss: 367.9249 - val_mae: 10.0977\n",
      "Epoch 37/50\n",
      "\u001b[1m1488/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 340.0932 - mae: 9.4521\n",
      "Epoch 37: val_loss did not improve from 367.44455\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - loss: 340.0930 - mae: 9.4521 - val_loss: 367.5304 - val_mae: 10.1114\n",
      "Epoch 38/50\n",
      "\u001b[1m1487/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 340.4268 - mae: 9.4556\n",
      "Epoch 38: val_loss did not improve from 367.44455\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - loss: 340.4269 - mae: 9.4556 - val_loss: 367.7462 - val_mae: 10.1010\n",
      "Epoch 39/50\n",
      "\u001b[1m1487/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 339.7027 - mae: 9.4435\n",
      "Epoch 39: val_loss did not improve from 367.44455\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - loss: 339.7020 - mae: 9.4435 - val_loss: 367.4476 - val_mae: 10.0840\n",
      "Epoch 40/50\n",
      "\u001b[1m1486/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 342.5552 - mae: 9.5145\n",
      "Epoch 40: val_loss improved from 367.44455 to 367.25549, saving model to ./models/hybrid_model.keras\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - loss: 342.5493 - mae: 9.5144 - val_loss: 367.2555 - val_mae: 10.0806\n",
      "Epoch 41/50\n",
      "\u001b[1m1486/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 339.4842 - mae: 9.4383\n",
      "Epoch 41: val_loss did not improve from 367.25549\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - loss: 339.4836 - mae: 9.4383 - val_loss: 367.5879 - val_mae: 10.0565\n",
      "Epoch 42/50\n",
      "\u001b[1m1488/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 339.0431 - mae: 9.4292\n",
      "Epoch 42: val_loss did not improve from 367.25549\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - loss: 339.0432 - mae: 9.4292 - val_loss: 367.4955 - val_mae: 10.0589\n",
      "Epoch 43/50\n",
      "\u001b[1m1488/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 338.8755 - mae: 9.4245\n",
      "Epoch 43: val_loss did not improve from 367.25549\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - loss: 338.8752 - mae: 9.4244 - val_loss: 367.6971 - val_mae: 10.0583\n",
      "Epoch 44/50\n",
      "\u001b[1m1488/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 387.8476 - mae: 10.0868\n",
      "Epoch 44: val_loss did not improve from 367.25549\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - loss: 387.8657 - mae: 10.0873 - val_loss: 393.2421 - val_mae: 10.7849\n",
      "Epoch 45/50\n",
      "\u001b[1m1488/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 369.6817 - mae: 10.1749\n",
      "Epoch 45: val_loss did not improve from 367.25549\n",
      "\u001b[1m1489/1489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - loss: 369.6809 - mae: 10.1749 - val_loss: 389.8968 - val_mae: 10.6385\n",
      "Epoch 45: early stopping\n",
      "\u001b[1m9924/9924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - loss: 352.4277 - mae: 10.2141\n",
      "Test Mean Absolute Error: 10.039456367492676\n",
      "\u001b[1m9924/9924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step\n",
      "Mean Absolute Error for each column:\n",
      "[17.377876   3.7845135  0.3331272  8.261245  20.440157 ]\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"./models/hybrid_model.keras\", monitor='val_loss', save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "# Define input layer\n",
    "input_layer = Input(shape=(X_train.shape[1], 1))\n",
    "\n",
    "# CNN model\n",
    "conv_layer = Conv1D(filters=32, kernel_size=3, activation='relu')(input_layer)\n",
    "maxpool_layer = MaxPooling1D(pool_size=2)(conv_layer)\n",
    "flatten_layer = Flatten()(maxpool_layer)\n",
    "dense_cnn = Dense(32, activation='relu')(flatten_layer)\n",
    "\n",
    "# BiLSTM model\n",
    "lstm_layer = LSTM(64, activation='relu')(input_layer)\n",
    "# lstm_layer2 = LSTM(32, activation='relu', return_sequences=False)(lstm_layer)\n",
    "dense_lstm = Dense(32, activation='relu')(lstm_layer)\n",
    "\n",
    "# Concatenate CNN and BiLSTM outputs\n",
    "concatenated = Concatenate()([dense_cnn, dense_lstm])\n",
    "\n",
    "# Output layer\n",
    "output_layer = Dense(5)(concatenated)\n",
    "\n",
    "# Create the ensemble model\n",
    "hybrid_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "hybrid_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "history = hybrid_model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=50,\n",
    "    batch_size=512,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")\n",
    "\n",
    "loss, mae = hybrid_model.evaluate(X_test, Y_test)\n",
    "print(\"Test Mean Absolute Error:\", mae)\n",
    "\n",
    "Y_pred = hybrid_model.predict(X_test)\n",
    "\n",
    "mae_columns = mean_absolute_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "print(\"Mean Absolute Error for each column:\")\n",
    "print(mae_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
